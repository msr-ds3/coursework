# Intro to Statistics and Machine Learning

## Day 1
  * See the [Statistical Inference & Hypothesis Testing](intro_to_stats.pptx) slides
  * Review the [statistical inference Rmarkdown file](statistical_inference.Rmd) (preview the output [here](http://htmlpreview.github.io/?https://github.com/msr-ds3/coursework/blob/master/week2/statistical_inference.html))
  * Interactive demos from the slides:
    * [Student t-distribution](http://rpsychologist.com/d3/tdist/)
    * From the [Seeing theory](http://students.brown.edu/seeing-theory/) site:
      * [Random variables](http://students.brown.edu/seeing-theory/probability-distributions/index.html#section1)
      * [Basic probability](http://students.brown.edu/seeing-theory/basic-probability/index.html)
      * [Central limit theorem](http://students.brown.edu/seeing-theory/probability-distributions/index.html#section3)
      * [Confidence intervals](http://students.brown.edu/seeing-theory/frequentist-inference/index.html#section2)
    * An [interactive tutorial on sampling variability in polling](http://rocknpoll.graphics)
  * Read Chapter 7 of [Introduction to Statistical Thinking (With R, Without Calculus)](http://pluto.huji.ac.il/~msby/StatThink/) (IST) for a recap of sampling distributions. Feel free to execute code in the book along the way.
  * Do question 7.1
  * Read Chapter 9 of of IST
  * Do questions 9.1 and 9.2
  * Go through the [sampling means Rmarkdown file](sampling_means_HW.Rmd) (preview the output [here](http://htmlpreview.github.io/?https://github.com/msr-ds3/coursework/blob/master/week2/sampling_means_HW.html)), and complete the last exercise
  * Read Chapters 10 and 11 of IST
  * For background:
    *  Chapter 4 has a good review of population distributions, expectations, and variance
    *  Chapter 5 has a recap of random variables
    *  Chapter 6 has more information on the normal distribution
  * See section 4 of [Mindless Statistics](http://library.mpib-berlin.mpg.de/ft/gg/GG_Mindless_2004.pdf) and [this article](https://link.springer.com/article/10.1007/s10654-016-0149-3) for some warnings on misinterpretations of p-values

<!--
  * Review the third chapter of [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/index.html) and work on the associated lab
-->


## Day 2

  * Review the [Prediction and Regression](Lecture%202%20Prediction%20regression%202018.pptx) slides
  * Do [HW2](hw2%20DS3%202018.docx) where you'll learn all about regression and Orange Juice!
  * See this notebook on [linear models](https://github.com/msr-ds3/coursework/blob/master/week2/linear_models.ipynb) with the `modelr` from the tidyverse and this one on [model evaluation](model_evaluation.ipynb) 
  * Read Chapter 18 of [R for Data Science](http://r4ds.had.co.nz) on modeling in R
  * Reference:
    * [Formula syntax in R](https://cran.r-project.org/doc/manuals/R-intro.html#Formulae-for-statistical-models)
    * Dan's interactive [Visual Least Squares](http://www.dangoldstein.com/dsn/archives/2006/03/every_wonder_ho.html) tool
    * Some background on elasticity: [blog post](http://www.salemmarafi.com/business/price-elasticity/), [Khan Academy video](https://www.khanacademy.org/economics-finance-domain/microeconomics/elasticity-tutorial/price-elasticity-tutorial/v/price-elasticity-of-demand)
    * A slide deck on [log transformations in regression](http://home.wlu.edu/%7Egusej/econ398/notes/logRegressions.pdf)
    * Chapter 3 of [Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/) on regression
    * Also covered in Chapter 14 of [Introduction to Statistical Thinking](http://pluto.huji.ac.il/~msby/StatThink/)





